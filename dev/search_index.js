var documenterSearchIndex = {"docs":
[{"location":"api/#dtattreatments","page":"Api","title":"DataTreatments","text":"","category":"section"},{"location":"api/#treatments","page":"Api","title":"Treatments","text":"","category":"section"},{"location":"api/#windowing","page":"Api","title":"Windowing","text":"","category":"section"},{"location":"api/#DataTreatments.FeatureId","page":"Api","title":"DataTreatments.FeatureId","text":"FeatureId <: AbstractFeatureId\n\nA metadata container for individual features in a processed dataset.\n\nThis struct stores information about each feature column, including the source variable name, the transformation function applied, and the window number. It is designed for:\n\nExperiment documentation: All feature extraction parameters are preserved for reproducibility\nFeature selection: Metadata enables intelligent feature filtering and selection strategies\nTraceability: Each feature can be traced back to its source variable and transformation\n\nFields\n\nvname::Symbol: Source variable name from the original dataset\nfeat::Base.Callable: Feature extraction function (e.g., mean, std, maximum)\nnwin::Int64: Window number (1 for single window, >1 for multiple windows)\n\nExamples\n\n# Single window feature\nfid = FeatureId(:temperature, mean, 1)\n# Displays as: mean(temperature)\n\n# Multi-window feature\nfid = FeatureId(:pressure, maximum, 3)\n# Displays as: maximum(pressure)_w3\n\n# Access metadata\nget_vname(fid)    # :pressure\nget_feature(fid)  # maximum\nget_nwin(fid)     # 3\n\nSee Also\n\nDataTreatment: Main container using FeatureId for metadata\n\n\n\n\n\n","category":"type"},{"location":"api/#DataTreatments.DataTreatment","page":"Api","title":"DataTreatments.DataTreatment","text":"DataTreatment{T, S} <: AbstractDataTreatment\n\nA container for processed multidimensional data with complete metadata for reproducibility.\n\nThis struct stores the transformed dataset along with all processing parameters, ensuring full experiment documentation and reproducibility.\n\nFields\n\ndataset::AbstractMatrix{T}: Processed flat feature matrix (samples Ã— features)\nfeatureid::Vector{FeatureId}: Metadata for each feature column (enables feature selection)\nreducefunc::Base.Callable: Reduction function used (for :reducesize mode)\naggrtype::Symbol: Processing type (:aggregate or :reducesize)\n\nType Parameters\n\nT: Element type of the output dataset\nS: Core element type for nested structures\n\nConstructor\n\nDataTreatment(\n    X::Union{AbstractMatrix, AbstractDataFrame},\n    aggrtype::Symbol;\n    vnames::Vector{<:ValidVnames},\n    win::Union{Base.Callable, Tuple{Vararg{Base.Callable}}},\n    features::Tuple{Vararg{Base.Callable}}=(maximum, minimum, mean),\n    reducefunc::Base.Callable=mean,\n)\n\nArguments\n\nX: Input data (Matrix or DataFrame with multidimensional elements)\naggrtype: Processing mode (:aggregate or :reducesize)\nvnames: Variable names for feature identification\nwin: Window function(s) for data partitioning\nfeatures: Tuple of statistical functions to apply (default: (maximum, minimum, mean))\nreducefunc: Reduction function for :reducesize mode (default: mean)\n\nProcessing Modes\n\n:reducesize Mode\n\nApplies multiple feature functions to windowed regions, preserving the dataset structure. Each element is reduced but the matrix dimensions are maintained.\n\nXmatrix = fill(rand(200, 120), 100, 10)  # 100 samples, 10 variables\nwin = splitwindow(nwindows=4)\nfeatures = (mean, std, maximum)\n\ndt = DataTreatment(Xmatrix, :reducesize; \n                   vnames=Symbol.(\"var\", 1:10),\n                   win=(win,), \n                   features=features)\n# Each 200Ã—120 element becomes 4Ã—4, resulting in 100Ã—10 output\n\n:aggregate Mode\n\nFlattens multidimensional data into a single feature matrix suitable for ML models. Applies multiple features across windows and concatenates results.\n\ndt = DataTreatment(Xmatrix, :aggregate;\n                   vnames=Symbol.(\"var\", 1:10),\n                   win=(win,),\n                   features=features)\n# Returns 100Ã—(10Ã—3Ã—16) = 100Ã—480 flat matrix\n# 10 vars Ã— 3 features Ã— 16 windows (4Ã—4 grid)\n\nExamples\n\nBasic Usage with DataFrame\n\nusing DataFrames\n\n# Create dataset with multidimensional elements\ndf = DataFrame(\n    channel1 = [rand(200, 120) for _ in 1:1000],\n    channel2 = [rand(200, 120) for _ in 1:1000],\n    channel3 = [rand(200, 120) for _ in 1:1000]\n)\n\n# Define processing parameters\nwin = adaptivewindow(nwindows=6, overlap=0.15)\nfeatures = (mean, std, maximum, minimum, median)\n\n# Process to tabular format\ndt = DataTreatment(df, :reducesize; \n                   win=(win,), \n                   features=features)\n\n# Access processed data\nX_flat = get_dataset(dt)        # Flat feature matrix\nfeature_ids = get_featureid(dt) # Feature metadata\n\nFeature Selection Using Metadata\n\n# Get all feature metadata\nfeature_ids = get_featureid(dt)\n\n# Select specific features\nmean_features = findall(fid -> get_feature(fid) == mean, feature_ids)\nX_means = dt.dataset[:, mean_features]\n\n# Select features from specific variable\nch1_features = findall(fid -> get_vname(fid) == :channel1, feature_ids)\nX_ch1 = dt.dataset[:, ch1_features]\n\n# Select features from specific windows\nearly_windows = findall(fid -> get_nwin(fid) <= 3, feature_ids)\nX_early = dt.dataset[:, early_windows]\n\nReproducibility and Documentation\n\n# All parameters are stored for experiment reproduction\ndt = DataTreatment(df, :reducesize; win=(win,), features=features)\n\n# Extract processing metadata\naggrtype = get_aggrtype(dt)       # :reducesize\nreduction = get_reducefunc(dt)    # mean\nvar_names = get_vnames(dt)        # [:channel1, :channel2, :channel3]\nfeat_funcs = get_features(dt)     # (mean, std, maximum, minimum, median)\nn_windows = get_nwindows(dt)      # 6\n\n# Document experiment\nprintln(\"Processing: $aggrtype mode\")\nprintln(\"Variables: $(join(var_names, \", \"))\")\nprintln(\"Features: $(join(nameof.(feat_funcs), \", \"))\")\nprintln(\"Windows: $n_windows per dimension\")\n\nAccessor Functions\n\nget_dataset(dt): Extract the processed feature matrix\nget_featureid(dt): Get feature metadata vector\nget_reducefunc(dt): Get the reduction function used\nget_aggrtype(dt): Get the processing mode\nget_vnames(dt): Get unique variable names\nget_features(dt): Get unique feature functions\nget_nwindows(dt): Get maximum window number\n\nIndexing\n\nDataTreatment supports array-like indexing:\n\ndt[1, :]      # First sample (row)\ndt[:, 1]      # First feature (column)\ndt[1:10, :]   # First 10 samples\nsize(dt)      # Dataset dimensions\nlength(dt)    # Number of features\n\nSee Also\n\nFeatureId: Individual feature metadata\naggregate: Multi-element aggregation\nreducesize: Flatten to tabular format\n@evalwindow: Window evaluation macro\n\n\n\n\n\n","category":"type"},{"location":"api/#DataTreatments.reducesize","page":"Api","title":"DataTreatments.reducesize","text":"reducesize(X::AbstractArray, intervals::Tuple{Vararg{Vector{UnitRange{Int64}}}}[; reducefunc::Base.Callable=mean]) -> AbstractArray\n\nApply window-based size-reduction to each element of an array.\n\nThis function is designed for arrays where each element is itself an array (e.g., Matrix{Matrix{Float64}}).\n\nArguments\n\nX::AbstractArray: Input array where each element is an array to be size-reduced\nintervals::Tuple{Vararg{Vector{UnitRange{Int64}}}}: Window definitions for aggregation\nreducefunc::Base.Callable=mean: Function to apply to each window (default: mean)\n\nReturns\n\nAbstractArray: Array with same outer dimensions as X, each element containing size-reduced results\n\nExample\n\nX = rand(100, 120)\nXmatrix = fill(X, 100, 10)\nwfunc = splitwindow(nwindows=3)\nintervals = @evalwindow X wfunc\nresult = reducesize(Xmatrix, intervals; reducefunc=std)\n\n\n\n\n\n","category":"function"},{"location":"api/#DataTreatments.aggregate","page":"Api","title":"DataTreatments.aggregate","text":"aggregate(X::AbstractArray, intervals::Tuple{Vararg{Vector{UnitRange{Int64}}}}[; features::Tuple{Vararg{Base.Callable}}=(mean,)]) -> AbstractArray\n\nFlatten nested arrays by applying multiple feature functions to windowed regions.\n\nThis function takes a matrix of arrays (e.g., Matrix{Matrix{Float64}}) and produces a single flat matrix where each row corresponds to a row in X, and columns contain flattened features computed from windowed aggregations.\n\nUse Case\n\nThis function enables the analysis of datasets containing n-dimensional elements (such as images,  time series, or spectrograms) with machine learning models that require tabular input. It transforms  complex multi-dimensional data into a flat feature matrix suitable for standard ML algorithms.\n\nArguments\n\nX::AbstractArray: Input array where each element is an array (e.g., Matrix{Matrix{Float64}})\nintervals::Tuple{Vararg{Vector{UnitRange{Int64}}}}: Window definitions for aggregation\nfeatures::Tuple{Vararg{Base.Callable}}=(mean,): Tuple of functions to compute on each window\n\nReturns\n\nAbstractArray: Flattened array with dimensions (nrows(X), ncols(X) Ã— n_features Ã— n_windows) where each element is of type core_eltype(X)\n\nDetails\n\nThe output columns are organized as: for each column in X, all features are computed for all windows, with results concatenated in the order: [col1_feat1_win1, col1_feat1_win2, col1_feat2_win1, ...]\n\nExample\n\nX = rand(100, 120)\nXmatrix = fill(X, 100, 10)\nwfunc = splitwindow(nwindows=3)\nintervals = @evalwindow X wfunc\nfeatures = (mean, maximum)\nresult = aggregate(Xmatrix, intervals; features)\n\n\n\n\n\n","category":"function"},{"location":"api/#DataTreatments.movingwindow","page":"Api","title":"DataTreatments.movingwindow","text":"movingwindow(; winsize::Int64[, winstep::Int64]) -> Function\n\nCreates a moving (sliding) window function with fixed window size and step.\n\nKeyword Arguments\n\nwinsize::Int64: Size of each window\nwinstep::Int64: Step between consecutive windows (defaults to winsize if 0)\n\nReturns\n\nFunction: A function that takes npoints::Int64 and returns Vector{UnitRange{Int64}}\n\nExample\n\nwfunc = movingwindow(winsize=10, winstep=5)\nwindows = wfunc(100)  # apply to sequence of length 100\n\nUse with macro\n\nA = rand(200)\nwindows = @evalwindow A movingwindow(winsize=10, winstep=5)\n\n\n\n\n\n","category":"function"},{"location":"api/#DataTreatments.wholewindow","page":"Api","title":"DataTreatments.wholewindow","text":"wholewindow() -> Function\n\nCreates a window function that returns a single window covering the entire sequence.\n\nReturns\n\nFunction: A function that takes npoints::Int64 and returns a single window [1:npoints]\n\nExample\n\nwfunc = wholewindow()\nwindows = wfunc(100)  # returns [1:100]\n\nUse with macro\n\nA = rand(200)\nwindows = @evalwindow A wholewindow()\n\n\n\n\n\n","category":"function"},{"location":"api/#DataTreatments.splitwindow","page":"Api","title":"DataTreatments.splitwindow","text":"splitwindow(; nwindows::Int64) -> Function\n\nCreates a window function that splits the sequence into a fixed number of non-overlapping windows.\n\nKeyword Arguments\n\nnwindows::Int64: Number of windows to create\n\nReturns\n\nFunction: A function that takes npoints::Int64 and returns Vector{UnitRange{Int64}}\n\nExample\n\nwfunc = splitwindow(nwindows=5)\nwindows = wfunc(100)  # splits into 5 equal windows\n\nUse with macro\n\nA = rand(200)\nwindows = @evalwindow A splitwindow(nwindows=5)\n\n\n\n\n\n","category":"function"},{"location":"api/#DataTreatments.adaptivewindow","page":"Api","title":"DataTreatments.adaptivewindow","text":"adaptivewindow(; nwindows::Int64[, overlap::Float64=0.0]) -> Function\n\nCreates a window function that adaptively divides the sequence into windows with optional overlap.\n\nKeyword Arguments\n\nnwindows::Int64: Number of windows to create\noverlap::Float64: Relative overlap between windows (0.0 to 1.0), defaults 0.0.\n\nReturns\n\nFunction: A function that takes npoints::Int64 and returns Vector{UnitRange{Int64}}\n\nExample\n\nwfunc = adaptivewindow(nwindows=5, overlap=0.2)\nwindows = wfunc(100)  # 5 windows with 20% overlap\n\nUse with macro\n\nA = rand(200)\nwindows = @evalwindow A adaptivewindow(nwindows=5, overlap=0.2)\n\n\n\n\n\n","category":"function"},{"location":"api/#DataTreatments.@evalwindow","page":"Api","title":"DataTreatments.@evalwindow","text":"@evalwindow(X, winfuncs...) -> Tuple{Vararg{Vector{UnitRange{Int64}}}}\n\nApply window functions to each dimension of an array.\n\nThis macro evaluates window functions for each dimension of an array, automatically  determining the appropriate number of points from the array's size. If fewer window  functions are provided than dimensions, the last function is reused for remaining dimensions.\n\nArguments\n\nX: Input array whose dimensions determine window parameters\nwinfuncs...: One or more window functions (e.g., movingwindow(), splitwindow(), adaptivewindow())\n\nReturns\n\nTuple{Vararg{Vector{UnitRange{Int64}}}}: Tuple of vectors containing window ranges for each dimension\n\nBehavior\n\nEach window function is applied to the corresponding dimension size\nIf length(winfuncs) < ndims(X), the last function is repeated for remaining dimensions\nWindow functions must be created using movingwindow, splitwindow, adaptivewindow, or wholewindow\n\nExamples\n\nSingle dimension\n\nX = rand(200)\nwindows = @evalwindow X movingwindow(winsize=50, winstep=25)\n\nTwo dimensions with different windows\n\nX = rand(200, 120)\nwindows = @evalwindow X splitwindow(nwindows=4) adaptivewindow(nwindows=3, overlap=0.1)\n# First dimension: 4 non-overlapping windows\n\nReusing window function for multiple dimensions\n\nX = rand(100, 120, 80)\nwindows = @evalwindow X splitwindow(nwindows=5)\n\nSee Also\n\nmovingwindow: Fixed-size sliding windows\nsplitwindow: Equal non-overlapping windows\nadaptivewindow: Windows with overlap\nwholewindow: Single window covering entire dimension\n\n\n\n\n\n","category":"macro"},{"location":"featureset/#featuresets","page":"FeatureSet","title":"Featuresets","text":"","category":"section"},{"location":"featureset/#Basic-Statistics","page":"FeatureSet","title":"Basic Statistics","text":"Standard statistical measures: maximum, minimum, mean, median, std, cov","category":"section"},{"location":"featureset/#Catch22-Features","page":"FeatureSet","title":"Catch22 Features","text":"Canonical time-series characteristics covering:\n\nDistribution properties and extreme events\nLinear and nonlinear autocorrelation structures  \nForecasting performance and scaling properties\nSymbolic dynamics and transition patterns","category":"section"},{"location":"featureset/#Predefined-Feature-Sets","page":"FeatureSet","title":"Predefined Feature Sets","text":"base_set: Minimal statistical features (4 features)\ncatch9: Curated subset combining statistics + key Catch22 (9 features)  \ncatch22_set: Complete Catch22 suite (22 features)\ncomplete_set: All features combined (28 features)","category":"section"},{"location":"featureset/#References","page":"FeatureSet","title":"References","text":"The Catch22 features are based on the Canonical Time-series Characteristics:\n\nRepository: https://github.com/DynamicsAndNeuralSystems/catch22\nPaper: Lubba, C.H., Sethi, S.S., Knaute, P. et al. \"catch22: CAnonical Time-series CHaracteristics.\" Data Min Knowl Disc 33, 1821â€“1852 (2019). https://doi.org/10.1007/s10618-019-00647-x","category":"section"},{"location":"featureset/#All-Catch22-Features","page":"FeatureSet","title":"All Catch22 Features","text":"","category":"section"},{"location":"featureset/#DataTreatments.base_set","page":"FeatureSet","title":"DataTreatments.base_set","text":"base_set\n\nA minimal feature set containing only basic statistical measures for time series analysis.\n\nFeatures\n\nmaximum: Maximum value in the time series\nminimum: Minimum value in the time series  \nmean   : Arithmetic mean of the time series\nstd    : Standard deviation of the time series\n\n\n\n\n\n","category":"constant"},{"location":"featureset/#DataTreatments.catch9","page":"FeatureSet","title":"DataTreatments.catch9","text":"catch9\n\nA curated subset of 9 features combining basic statistics with Symbolic Catch22 measures,\n\nFeatures\n\nBasic statistics: maximum, minimum, mean, median, std\nSymbolic Catch22 features:\nstretch_high       : Measures persistence of high values\nstretch_decreasing : Captures decreasing trend patterns\nentropy_pairs      : Quantifies local pattern complexity\ntransition_variance: Measures state transition variability\n\nReferences\n\nThe Catch22 features are based on the CAnonical Time-series CHaracteristics from:\n\nRepository: https://github.com/DynamicsAndNeuralSystems/catch22\nArticle:    https://doi.org/10.1007/s10618-019-00647-x\nAuthor: Carl H. Lubba et al\n\n\n\n\n\n","category":"constant"},{"location":"featureset/#DataTreatments.catch22_set","page":"FeatureSet","title":"DataTreatments.catch22_set","text":"catch22_set\n\nThe complete Catch22 feature set. Each feature captures different aspects of time series dynamics including correlation structure, distribution properties and temporal patterns.\n\nFeature Categories\n\nDistribution shape:  mode_5, mode_10\nExtreme event timing: outlier_timing_pos, outlier_timing_neg\nLinear autocorrelation: acf_timescale, acf_first_min, low_freq_power, centroid_freq\nSimple forecasting: forecast_error\nIncremental differences: whiten_timescale, high_fluctuation\nSymbolic stretch_high, stretch_decreasing, entropy_pairs, transition_variance\nNonlinear autocorrelation: ami2, trev\nLinear autocorrelation structure: ami_timescale, periodicity\nSelf-affine scaling: rs_range, dfa\nOther: embedding_dist\n\nReferences\n\nThe Catch22 features are based on the CAnonical Time-series CHaracteristics from:\n\nRepository: https://github.com/DynamicsAndNeuralSystems/catch22\nArticle:    https://doi.org/10.1007/s10618-019-00647-x\nAuthor: Carl H. Lubba et al\n\n\n\n\n\n","category":"constant"},{"location":"featureset/#DataTreatments.complete_set","page":"FeatureSet","title":"DataTreatments.complete_set","text":"complete_set\n\nThe most comprehensive feature set combining basic statistical measures, covariance analysis, and the full Catch22 suite.\n\nFeatures\n\nBasic statistics: maximum, minimum, mean, median, std, cov\nDistribution shape:  mode_5, mode_10\nExtreme event timing: outlier_timing_pos, outlier_timing_neg\nLinear autocorrelation: acf_timescale, acf_first_min, low_freq_power, centroid_freq\nSimple forecasting: forecast_error\nIncremental differences: whiten_timescale, high_fluctuation\nSymbolic stretch_high, stretch_decreasing, entropy_pairs, transition_variance\nNonlinear autocorrelation: ami2, trev\nLinear autocorrelation structure: ami_timescale, periodicity\nSelf-affine scaling: rs_range, dfa\nOther: embedding_dist\n\n\n\n\n\n","category":"constant"},{"location":"featureset/#DataTreatments.mode_5","page":"FeatureSet","title":"DataTreatments.mode_5","text":"DN_HistogramMode_5(x::AbstractVector{Union{Float64, Int}}) # For example\n\nAn alternative to catch22(:DN_HistogramMode_5](x). All features, such as DN_HistogramMode_5, are exported as Features and can be evaluated by calling their names.\n\nExamples\n\nð± = Catch22.testdata[:test]\nf = DN_HistogramMode_5(ð±)\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.mode_10","page":"FeatureSet","title":"DataTreatments.mode_10","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.embedding_dist","page":"FeatureSet","title":"DataTreatments.embedding_dist","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.acf_timescale","page":"FeatureSet","title":"DataTreatments.acf_timescale","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.acf_first_min","page":"FeatureSet","title":"DataTreatments.acf_first_min","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.ami2","page":"FeatureSet","title":"DataTreatments.ami2","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.trev","page":"FeatureSet","title":"DataTreatments.trev","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.outlier_timing_pos","page":"FeatureSet","title":"DataTreatments.outlier_timing_pos","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.outlier_timing_neg","page":"FeatureSet","title":"DataTreatments.outlier_timing_neg","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.whiten_timescale","page":"FeatureSet","title":"DataTreatments.whiten_timescale","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.forecast_error","page":"FeatureSet","title":"DataTreatments.forecast_error","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.ami_timescale","page":"FeatureSet","title":"DataTreatments.ami_timescale","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.high_fluctuation","page":"FeatureSet","title":"DataTreatments.high_fluctuation","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.stretch_decreasing","page":"FeatureSet","title":"DataTreatments.stretch_decreasing","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.stretch_high","page":"FeatureSet","title":"DataTreatments.stretch_high","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.entropy_pairs","page":"FeatureSet","title":"DataTreatments.entropy_pairs","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.rs_range","page":"FeatureSet","title":"DataTreatments.rs_range","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.dfa","page":"FeatureSet","title":"DataTreatments.dfa","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.low_freq_power","page":"FeatureSet","title":"DataTreatments.low_freq_power","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.centroid_freq","page":"FeatureSet","title":"DataTreatments.centroid_freq","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.transition_variance","page":"FeatureSet","title":"DataTreatments.transition_variance","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"featureset/#DataTreatments.periodicity","page":"FeatureSet","title":"DataTreatments.periodicity","text":"No documentation found for public binding TimeseriesFeatures.SuperFeatures.SuperFeature.\n\nSummary\n\nstruct TimeseriesFeatures.SuperFeatures.SuperFeature{F, G}\n\nFields\n\nfeature     :: F\nsuper       :: G\nname        :: Symbol\ndescription :: String\nkeywords    :: Vector{String}\n\nSupertype Hierarchy\n\nTimeseriesFeatures.SuperFeatures.SuperFeature{F, G} <: TimeseriesFeatures.SuperFeatures.AbstractSuperFeature <: TimeseriesFeatures.Features.AbstractFeature <: Function <: Any\n\n\n\n\n\n","category":"function"},{"location":"normalization/#Normalization","page":"Normalization","title":"Normalization","text":"","category":"section"},{"location":"normalization/#dtattreatments","page":"Normalization","title":"Methods Api","text":"","category":"section"},{"location":"normalization/#DataTreatments.element_norm","page":"Normalization","title":"DataTreatments.element_norm","text":"element_norm(X::AbstractArray, n::Base.Callable) -> AbstractArray\n\nNormalize a single array element using global statistics computed across all elements.\n\nArguments\n\nX::AbstractArray: Input array of any dimension (vector, matrix, tensor, etc.)\nn::Base.Callable: Normalization function constructor that computes parameters from data\n\nExamples\n\nX = rand(100, 50)\nX_norm = element_norm(X, zscore())      # Z-score normalization\nX_norm = element_norm(X, minmax())     # Min-max scaling\nX_norm = element_norm(X, center())      # Mean centering\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.tabular_norm","page":"Normalization","title":"DataTreatments.tabular_norm","text":"tabular_norm(X::AbstractArray, n::Base.Callable; [dim::Symbol=:col]) -> AbstractArray\n\nNormalize a tabular array by computing separate normalization parameters for each column or row.\n\nArguments\n\nX::AbstractArray: Input array (typically a matrix where columns represent features)\nn::Base.Callable: Normalization function constructor (e.g., zscore(), minmax())\ndim::Symbol=:col: Dimension along which to normalize\n:col (default): Normalize each column independently (column-wise)\n:row: Normalize each row independently (row-wise)\n\nExamples\n\n# Column-wise normalization (default) - each feature normalized independently\nX = rand(100, 50)  # 100 samples, 50 features\nX_norm = tabular_norm(X, zscore())\n# Each column: mean â‰ˆ 0, std â‰ˆ 1\n\n# Row-wise normalization - each sample normalized independently\nX_scaled = tabular_norm(X, minmax(); dim=:row)\n# Each row scaled to [0, 1] independently\n\nNotes\n\nEach column/row uses only its own statistics, not global statistics\nAutomatically converts Real arrays to Float64\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.grouped_norm","page":"Normalization","title":"DataTreatments.grouped_norm","text":"grouped_norm(X::AbstractArray, n::Base.Callable; featvec::Vector) -> AbstractArray\n\nNormalize grouped columns of a dataset by applying the same normalization coefficient to all columns generated by the same feature/transform.\n\nArguments\n\nX::AbstractArray{<:AbstractFloat}: Tabular dataset (observations Ã— features).\nn::Base.Callable: Normalization constructor (e.g. zscore(), minmax()).\nfeatvec::Vector{<:Base.Callable}: Feature functions associated with each column in X. Columns sharing the same callable form a group and reuse the same normalization statistics.\n\nExamples\n\n# Dataset with features from 2 variables and 2 transforms\nX = rand(100, 4)  # 100 samples, 4 features\nfeatvec = [mean, mean, std, std]  # First 2 cols are means, last 2 are stds\n\n# Normalize: all mean-based columns share normalization, std-based share another\nX_norm = grouped_norm(X, zscore(); featvec)\n# Columns 1-2: normalized together (mean â‰ˆ 0, std â‰ˆ 1 across both)\n# Columns 3-4: normalized together (mean â‰ˆ 0, std â‰ˆ 1 across both)\n\n# With windowed features\nwin = splitwindow(nwindows=3)\nfeatures = (mean, maximum)\ndt = DataTreatment(X_nested, :aggregate; win=(win,), features)\n# Each variable produces 3Ã—2=6 features: mean_w1, mean_w2, mean_w3, max_w1, max_w2, max_w3\n\nX_grouped = grouped_norm(dt.dataset, minmax(); featvec=get_vecfeatures(dt.featureid))\n# All mean features normalized together, all max features normalized together\n\nNotes\n\nReturns a new array; use grouped_norm! for in-place normalization\nColumns are grouped by feature function identity\nEach group computes normalization statistics from all values across its columns\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.grouped_norm!","page":"Normalization","title":"DataTreatments.grouped_norm!","text":"grouped_norm!(X::AbstractArray, n::Base.Callable; featvec::Vector) -> Nothing\n\nIn-place version of grouped_norm. Modifies X directly by normalizing grouped  columns using the same normalization function for columns sharing the same feature type.\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.ds_norm","page":"Normalization","title":"DataTreatments.ds_norm","text":"ds_norm(X::AbstractArray{<:AbstractArray}, n::Base.Callable) -> AbstractArray\n\nNormalize a dataset composed of n-dimensional elements (e.g., sequences, time series, or images) by computing normalization parameters for each column of the outer array.\n\nArguments\n\nX::AbstractArray{<:AbstractArray}: Nested array structure where each element is an array\nOuter array typically represents (samples Ã— features/channels)\nInner arrays can be vectors, matrices, or tensors\nn::Base.Callable: Normalization function constructor (e.g., zscore(), minmax())\n\nExamples\n\n# Time series dataset: each element is a time series\nX = [rand(100) for _ in 1:50, _ in 1:3]  # 50 samples Ã— 3 channels\nX_norm = ds_norm(X, zscore())\n# Each channel normalized across all 50 time series\n\n# Image dataset: each element is an image (matrix)\nimages = [rand(28, 28) for _ in 1:100, _ in 1:1]  # 100 grayscale images\nimages_norm = ds_norm(images, minmax())\n# All images normalized using global min/max\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.zscore","page":"Normalization","title":"DataTreatments.zscore","text":"zscore(; [method::Symbol]) -> Function\n\nCreate a z-score normalization function that standardizes data by centering and scaling.\n\nArguments\n\nmethod::Symbol: Method for computing the z-score\n\nMethods\n\nStandard Z-Score (:std, default)\n\nCenters data to mean 0 and scales to standard deviation 1.\n\nz = fracx - musigma\n\nwhere Î¼ is the mean and Ïƒ is the standard deviation.\n\nRobust Z-Score (:robust)\n\nCenters data to median 0 and scales to median absolute deviation 1. More resistant to outliers than standard z-score.\n\nz = fracx - textmedian(x)textMAD(x)\n\nwhere MAD is the median absolute deviation.\n\nHalf-Normal Z-Score (:half)\n\nNormalizes to the standard half-normal distribution using minimum and half-standard deviation.\n\nz = fracx - min(x)sigma_texthalf\n\nwhere Ïƒ_half = Ïƒ / âˆš(1 - 2/Ï€).\n\nExamples\n\n# Standard z-score normalization\nX = rand(100, 50)\nX_norm = element_norm(X, zscore())\n# Result: mean â‰ˆ 0, std â‰ˆ 1\n\n# Robust z-score (resistant to outliers)\nX_robust = element_norm(X, zscore(method=:robust))\n# Result: median â‰ˆ 0, MAD â‰ˆ 1\n\n# Half-normal z-score\nX_half = element_norm(X, zscore(method=:half))\n# Result: minimum â‰ˆ 0, scaled by half-standard deviation\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.sigmoid","page":"Normalization","title":"DataTreatments.sigmoid","text":"sigmoid() -> Function\n\nCreate a sigmoid normalization function that maps data to the interval (0, 1).\n\nThe sigmoid (or logistic) function provides a smooth, S-shaped transformation that  maps the entire real line to the bounded interval (0, 1), with the steepest slope  at the mean of the data.\n\nFormula\n\nsigma(x) = frac11 + e^-fracx - musigma\n\nwhere:\n\nÎ¼ (mu) is the mean of the input data\nÏƒ (sigma) is the standard deviation of the input data\nThe output is bounded: 0 < Ïƒ(x) < 1\n\nExamples\n\n# Sigmoid normalization\nX = rand(100, 50)\nX_sigmoid = element_norm(X, sigmoid())\n# Result: all values in (0, 1), mean(X) â†’ 0.5\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.pnorm","page":"Normalization","title":"DataTreatments.pnorm","text":"norm(; [p::Real]) -> Function\n\nCreate a normalization function that scales data by the p-norm.\n\nThe p-norm normalization divides each element by the p-norm of the entire dataset, ensuring that the normalized data has unit p-norm. This is particularly useful for standardizing data magnitudes across different scales.\n\nArguments\n\np::Real: The norm order (default: 2)\np = 1: Manhattan norm (sum of absolute values)\np = 2(default): Euclidean norm (default, root sum of squares)\np = Inf: Infinity norm (maximum absolute value)\np > 0: General p-norm\n\nFormula\n\nGeneral p-norm (p â‰¥ 1):\n\nx_p = left(sum_i=1^n x_i^pright)^1p\n\nExamples\n\n# L2 norm (Euclidean, default)\nX = rand(100, 50)\nX_norm = element_norm(X, norm())\n# Result: â€–Xâ€–â‚‚ = 1\n\n# L1 norm (Manhattan)\nX_L1 = element_norm(X, norm(p=1))\n# Result: sum(abs, X) = 1\n\n# Lâˆž norm (Maximum)\nX_Linf = element_norm(X, norm(p=Inf))\n# Result: maximum(abs, X) = 1\n\n# Custom p-norm\nX_L4 = element_norm(X, norm(p=4))\n# Result: (sum(X.^4))^(1/4) = 1\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.scale","page":"Normalization","title":"DataTreatments.scale","text":"scale(; [factor::Symbol]) -> Function\n\nCreate a normalization function that scales data by a specified scale factor.\n\nScale normalization divides data by a characteristic scale measure, standardizing the spread or magnitude without necessarily centering the data. This is useful when you want to normalize variability but preserve the mean or baseline.\n\nArguments\n\nfactor::Symbol: Scale factor to use\n\nScale Factor Options\n\nStandard Deviation (:std, default)\n\nScale data to have standard deviation of 1.\n\nx_textscaled = fracxsigma\n\nwhere Ïƒ is the standard deviation.\n\nMedian Absolute Deviation (:mad)\n\nScale data to have median absolute deviation of 1.\n\nx_textscaled = fracxtextMAD(x)\n\nwhere MAD = median(|x - median(x)|).\n\nFirst Element (:first)\n\nScale data by the value of the first element.\n\nx_textscaled = fracxx_1\n\nInterquartile Range (:iqr)\n\nScale data to have interquartile range of 1.\n\nx_textscaled = fracxtextIQR(x)\n\nwhere IQR = Qâ‚ƒ - Qâ‚ (75th percentile - 25th percentile).\n\nExamples\n\n# Standard deviation scaling (default)\nX = rand(100, 50)\nX_scaled = element_norm(X, scale())\n# Result: std(X_scaled) â‰ˆ 1, mean unchanged\n\n# Robust scaling with MAD\nX_outliers = [1, 2, 3, 4, 100]  # Has outlier\nX_mad = element_norm(X_outliers, scale(factor=:mad))\n# More robust than std scaling\n\n# IQR scaling\nX_iqr = element_norm(X, scale(factor=:iqr))\n# Result: IQR(X_iqr) â‰ˆ 1\n\n# Baseline normalization (first element)\nprices = [100.0, 105.0, 98.0, 110.0]\nprices_norm = element_norm(prices, scale(factor=:first))\n# Result: [1.0, 1.05, 0.98, 1.10] - percentage of initial price\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.minmax","page":"Normalization","title":"DataTreatments.minmax","text":"minmax(; [lower::Real, upper::Real]) -> Function\n\nCreate a min-max normalization function that rescales data to a specified range.\n\nArguments\n\nlower::Real: Lower bound of the output range (default: 0.0)\nupper::Real: Upper bound of the output range (default: 1.0)\n\nFormula\n\nx_textscaled = textlower + fracx - x_minx_max - x_min cdot (textupper - textlower)\n\nThis maps the original range [xmin, xmax] to [lower, upper] via affine transformation.\n\nExamples\n\n# Standard min-max scaling to [0, 1]\nX = rand(100, 50)\nX_norm = element_norm(X, minmax())\n# Result: min â‰ˆ 0, max â‰ˆ 1\n\n# Custom range scaling to [-1, 1]\nX_scaled = element_norm(X, minmax(lower=-1.0, upper=1.0))\n# Result: min â‰ˆ -1, max â‰ˆ 1\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.center","page":"Normalization","title":"DataTreatments.center","text":"center(; [method::Symbol]) -> Function\n\nCreate a centering normalization function that shifts data to have zero central tendency.\n\nCentering (also known as mean/median centering or demeaning) translates data by  subtracting a measure of central tendency, shifting the distribution without changing  its spread or shape. This is useful for removing baseline offsets and focusing on  relative deviations.\n\nArguments\n\nmethod::Symbol: Centering method (default: :mean)\n:mean(default): Center around arithmetic mean (subtracts mean)\n:median: Center around median (subtracts median, more robust to outliers)\n\nFormula\n\nMean Centering (:mean, default)\n\nx_textcentered = x - barx\n\nMedian Centering (:median)\n\nx_textcentered = x - textmedian(x)\n\nExamples\n\nX = rand(100, 50)\nX_centered = element_norm(X, center())\n# Result: mean(X_centered) â‰ˆ 0, std unchanged\n\n# Median centering\nX_outliers = [1, 2, 3, 4, 100]  # Has outlier\nX_med = element_norm(X_outliers, center(method=:median))\n# Result: median(X_med) = 0, outlier less influential\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.unitpower","page":"Normalization","title":"DataTreatments.unitpower","text":"unitpower() -> Function\n\nCreate a normalization function that scales data to have unit root mean square (RMS) power.\n\nUnit power normalization divides each element by the root mean square (RMS) of the  entire dataset, ensuring that the normalized data has RMS = 1. This is commonly used  in signal processing to normalize signal power.\n\nFormula\n\nx_textnormalized = fracxtextRMS(x)\n\nwhere the Root Mean Square (RMS) is:\n\ntextRMS(x) = sqrtfrac1nsum_i=1^n x_i^2 = sqrttextmean(x^2)\n\nExamples\n\n# Unit power normalization\nX = rand(100, 50)\nX_norm = element_norm(X, unitpower())\n# Result: RMS(X_norm) = 1\n\n\n\n\n\n","category":"function"},{"location":"normalization/#DataTreatments.outliersuppress","page":"Normalization","title":"DataTreatments.outliersuppress","text":"outliersuppress(; [thr::Real]) -> Function\n\nCreate a normalization function that suppresses outliers by capping values beyond a threshold.\n\nOutlier suppression identifies values that deviate more than a specified number of  standard deviations from the mean and replaces them with the threshold boundary value. This technique reduces the influence of extreme values while preserving the sign and  general structure of the data.\n\nArguments\n\nthr::Real=5.0: Threshold in standard deviations (default: 5.0)\n\nThreshold choice\n\nLower thresholds more aggressively modify data\n\nUse thr=0.3 for typical outlier removal (3-sigma rule)\nUse thr=0.5 (default) for conservative outlier handling\n\nFormula\n\nx_textsuppressed = begincases\nmu + textthr cdot sigma  textif  x  mu + textthr cdot sigma \nmu - textthr cdot sigma  textif  x  mu - textthr cdot sigma \nx  textotherwise\nendcases\n\nwhere:\n\nÎ¼ is the mean of the data\nÏƒ is the standard deviation\nValues within [Î¼ - thrÂ·Ïƒ, Î¼ + thrÂ·Ïƒ] remain unchanged\n\nExamples\n\n# Default threshold (0.5 standard deviations)\nX = [1, 2, 3, 4, 5, 100]  # 100 is an outlier\nX_suppressed = element_norm(X, outliersuppress())\n# Result: [1, 2, 3, 4, 5, ~mean+5*std] - outlier capped\n\n# More aggressive suppression (3 std)\nX_aggressive = element_norm(X, outliersuppress(thr=0.3))\n# Caps values beyond mean Â± 3*std (more values affected)\n\n\n\n\n\n","category":"function"},{"location":"#DataTreatments.jl","page":"Home","title":"DataTreatments.jl","text":"A Julia package for processing datasets containing multidimensional elements through windowing and dimensionality reduction techniques.","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"DataTreatments.jl provides tools for working with matrices, or DataFrames where each element is itself a multidimensional object (vectors, matrices, or higher-dimensional arrays). It offers:\n\nWindowing functions for partitioning multidimensional data\nDimensionality reduction using feature extraction together with windowing\nTabular transformation through feature extraction to convert complex multidimensional datasets into flat feature matrices suitable for standard machine learning models\nComplete reproducibility by storing all processing parameters and feature metadata\n\nThis package is particularly useful when you need to apply traditional ML algorithms that require tabular input to datasets containing structured multidimensional elements like images, spectrograms, or time series segments.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.add(\"DataTreatments\")","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"using DataTreatments\n\n# Create a dataset with multidimensional elements\nX = rand(200, 120)  # Example: 200Ã—120 matrix (e.g., spectrogram)\nXmatrix = fill(X, 100, 10)  # 100Ã—10 dataset where each element is a 200Ã—120 matrix\n\n# Define windowing strategy\nwin = splitwindow(nwindows=4)  # Split into 4 equal windows per dimension\n\n# Compute intervals for the first element\nintervals = @evalwindow X win\n\n# Apply multiple statistical features to each window\nfeatures = (mean, std, maximum, minimum)\nresult = aggregate(Xmatrix, intervals; features)\n\n# Normalize the result\nresult_norm = aggregate(Xmatrix, intervals; features, norm=zscore())  # Z-score normalization","category":"section"},{"location":"#Core-Concepts","page":"Home","title":"Core Concepts","text":"","category":"section"},{"location":"#Windowing-Functions","page":"Home","title":"Windowing Functions","text":"DataTreatments provides several windowing strategies:","category":"section"},{"location":"#splitwindow-Equal-Non-Overlapping-Windows","page":"Home","title":"splitwindow - Equal Non-Overlapping Windows","text":"win = splitwindow(nwindows=3)\n# Divides data into 3 equal, non-overlapping segments","category":"section"},{"location":"#movingwindow-Fixed-Size-Sliding-Windows","page":"Home","title":"movingwindow - Fixed-Size Sliding Windows","text":"win = movingwindow(winsize=50, winstep=25)\n# Creates overlapping windows of size 50, advancing by 25 points","category":"section"},{"location":"#adaptivewindow-Windows-with-Controlled-Overlap","page":"Home","title":"adaptivewindow - Windows with Controlled Overlap","text":"win = adaptivewindow(nwindows=5, overlap=0.2)\n# Creates 5 windows with 20% overlap between consecutive windows","category":"section"},{"location":"#wholewindow-Single-Window-(Entire-Dimension)","page":"Home","title":"wholewindow - Single Window (Entire Dimension)","text":"win = wholewindow()\n# Creates a single window covering the entire dimension","category":"section"},{"location":"#Multi-Dimensional-Windowing","page":"Home","title":"Multi-Dimensional Windowing","text":"Use the @evalwindow macro to apply window functions to each dimension:\n\nX = rand(200, 120)\n\n# Apply same windowing to all dimensions\nintervals = @evalwindow X splitwindow(nwindows=4)\n\n# Apply different windowing per dimension\nintervals = @evalwindow X splitwindow(nwindows=4) movingwindow(winsize=40, winstep=20)","category":"section"},{"location":"#Feature-Extraction-Functions","page":"Home","title":"Feature Extraction Functions","text":"","category":"section"},{"location":"#reducesize-Apply-to-Dataset-Elements","page":"Home","title":"reducesize - Apply to Dataset Elements","text":"Xmatrix = fill(rand(200, 120), 100, 10)  # Dataset of matrices\nintervals = @evalwindow first(Xmatrix) splitwindow(nwindows=3)\n\n# Aggregate each element using reduce feature\nresult = reducesize(Xmatrix, intervals; reducefunc=mean)\n# Each element reduced from 200Ã—120 to a 3Ã—3 matrix per feature","category":"section"},{"location":"#aggregate-Flatten-to-Tabular-Format","page":"Home","title":"aggregate - Flatten to Tabular Format","text":"Xmatrix = fill(rand(200, 120), 100, 10)  # 100 samples, 10 variables\nintervals = @evalwindow first(Xmatrix) splitwindow(nwindows=4)\nfeatures = (mean, std, maximum, minimum)\n\nresult = aggregate(Xmatrix, intervals; features)\n# Returns 100Ã—640 matrix (10 vars Ã— 4 features Ã— 16 windows)","category":"section"},{"location":"#Normalization-Functions","page":"Home","title":"Normalization Functions","text":"DataTreatments provides flexible normalization strategies for different data structures:","category":"section"},{"location":"#Normalization-Methods","page":"Home","title":"Normalization Methods","text":"# Z-score normalization (mean=0, std=1)\nzscore()                    # Standard z-score\nzscore(method=:robust)      # Robust z-score (median, MAD)\nzscore(method=:half)        # Half-normal z-score\n\n# Min-max scaling\nminmax()                    # Scale to [0, 1]\nminmax(lower=-1, upper=1)   # Scale to custom range\n\n# Sigmoid transformation\nsigmoid()                   # Logistic sigmoid to (0, 1)\n\n# Centering\ncenter()                    # Center to mean=0\ncenter(method=:median)      # Center to median=0\n\n# Scaling\nscale()                     # Scale to std=1\nscale(factor=:mad)          # Scale by MAD\n\n# Power normalization\nunitpower()                 # Normalize to unit RMS power\n\n# P-norm normalization\npnorm(p=2)                  # L2 normalization (unit length)\n\n# Outlier suppression\noutliersuppress(thr=3.0)    # Cap outliers beyond threshold","category":"section"},{"location":"#Element-wise-Normalization","page":"Home","title":"Element-wise Normalization","text":"Normalize using global statistics across all elements:\n\nX = rand(100, 50)  # 100 samples, 50 features\n\n# Z-score: mean â‰ˆ 0, std â‰ˆ 1 globally\nX_norm = element_norm(X, zscore())","category":"section"},{"location":"#Tabular-Normalization","page":"Home","title":"Tabular Normalization","text":"Normalize each column or row independently:\n\nX = rand(100, 50)  # 100 samples, 50 features\n\n# Column-wise (each feature normalized independently)\nX_norm = tabular_norm(X, zscore(); dim=:col)\n# Each column: mean â‰ˆ 0, std â‰ˆ 1\n\n# Row-wise (each sample normalized independently)\nX_norm = tabular_norm(X, zscore(); dim=:row)\n# Each row: mean â‰ˆ 0, std â‰ˆ 1","category":"section"},{"location":"#Dataset-Normalization-(Nested-Arrays)","page":"Home","title":"Dataset Normalization (Nested Arrays)","text":"For datasets composed of n-dimensional elements:\n\n# Time series dataset: each element is a time series\nX = [rand(100) for _ in 1:50, _ in 1:3]  # 50 samples Ã— 3 channels\n\n# Each channel normalized across all 50 time series\nX_norm = ds_norm(X, zscore())","category":"section"},{"location":"#Grouped-Normalization","page":"Home","title":"Grouped Normalization","text":"Normalize columns that share the same feature type together:\n\n# Dataset with windowed features\ndt = DataTreatment(df, :aggregate; \n                   win=(splitwindow(nwindows=3),),\n                   features=(mean, std, maximum))\n\n# All mean-based features share normalization, std-based share another\nX_grouped = grouped_norm(dt.dataset, zscore(); \n                        featvec=get_vecfeatures(dt.featureid))","category":"section"},{"location":"#Integration-with-DataTreatment","page":"Home","title":"Integration with DataTreatment","text":"Apply normalization during data treatment:\n\n# During DataTreatment creation\ndt = DataTreatment(df, :aggregate;\n                   win=(win,),\n                   features=(mean, std),\n                   norm=zscore())","category":"section"},{"location":"#Data-Structures","page":"Home","title":"Data Structures","text":"","category":"section"},{"location":"#FeatureId-Feature-Metadata","page":"Home","title":"FeatureId - Feature Metadata","text":"A metadata container that stores information about each feature column for reproducibility and feature selection:\n\n# Created automatically by DataTreatment\ndt = DataTreatment(df, :reducesize; win=(win,), features=(mean, std, maximum))\n\n# Access feature metadata\nfeature_ids = get_featureid(dt)\n\n# Each FeatureId contains:\n# - vname: Source variable name\n# - feat: Feature function applied\n# - nwin: Window number\n\n# Use for feature selection\nmean_features = filter(fid -> get_feature(fid) == mean, feature_ids)\ntemp_features = filter(fid -> get_vname(fid) == :temperature, feature_ids)\nwindow1_features = filter(fid -> get_nwin(fid) == 1, feature_ids)","category":"section"},{"location":"#DataTreatment-Complete-Processing-Container","page":"Home","title":"DataTreatment - Complete Processing Container","text":"A comprehensive container that stores processed data along with all parameters for full reproducibility:\n\nusing DataFrames, Statistics\n\n# Create dataset\ndf = DataFrame(\n    channel1 = [rand(200, 120) for _ in 1:1000],\n    channel2 = [rand(200, 120) for _ in 1:1000],\n    channel3 = [rand(200, 120) for _ in 1:1000]\n)\n\n# Process with full parameter storage\nwin = adaptivewindow(nwindows=6, overlap=0.15)\nfeatures = (mean, std, maximum, minimum, median)\n\ndt = DataTreatment(df, :reducesize; \n                   win=(win,), \n                   features=features,\n                   norm=zscore())\n\n# Access processed data\nX_flat = get_dataset(dt)        # Flat feature matrix\nfeature_ids = get_featureid(dt) # Feature metadata\n\n# All parameters are stored for reproducibility\naggrtype = get_aggrtype(dt)     # :reducesize\nreduction = get_reducefunc(dt)   # mean (default)\nvar_names = get_vnames(dt)       # [:channel1, :channel2, :channel3]\nfeat_funcs = get_features(dt)    # (mean, std, maximum, minimum, median)\nn_windows = get_nwindows(dt)     # 6\n\n# Document experiment\nprintln(\"Processing: $aggrtype mode\")\nprintln(\"Variables: $(join(var_names, \", \"))\")\nprintln(\"Features: $(join(nameof.(feat_funcs), \", \"))\")\nprintln(\"Windows: $n_windows per dimension\")","category":"section"},{"location":"#API-Reference","page":"Home","title":"API Reference","text":"","category":"section"},{"location":"#Windowing-Functions-2","page":"Home","title":"Windowing Functions","text":"splitwindow(; nwindows::Int) - Equal non-overlapping windows\nmovingwindow(; winsize::Int, winstep::Int) - Fixed-size sliding windows\nadaptivewindow(; nwindows::Int, overlap::Float64) - Windows with overlap\nwholewindow() - Single window covering entire dimension","category":"section"},{"location":"#Processing-Functions","page":"Home","title":"Processing Functions","text":"aggregate(X, intervals; features=(mean,)) - Apply features to dataset elements\nreducesize(X, intervals; features=(mean,)) - Flatten to tabular format","category":"section"},{"location":"#Data-Structures-2","page":"Home","title":"Data Structures","text":"DataTreatment - Container for processed data with complete metadata\nFeatureId - Metadata for individual features (variable, function, window)","category":"section"},{"location":"#Accessor-Functions","page":"Home","title":"Accessor Functions","text":"get_dataset(dt) - Extract processed feature matrix\nget_featureid(dt) - Get feature metadata vector\nget_reducefunc(dt) - Get reduction function used\nget_aggrtype(dt) - Get processing mode\nget_vnames(dt) - Get unique variable names\nget_features(dt) - Get unique feature functions\nget_nwindows(dt) - Get maximum window number\nget_vname(fid) - Get variable name from FeatureId\nget_feature(fid) - Get feature function from FeatureId\nget_nwin(fid) - Get window number from FeatureId","category":"section"},{"location":"#Macros","page":"Home","title":"Macros","text":"@evalwindow(X, winfuncs...) - Evaluate window functions for array dimensions","category":"section"},{"location":"#Normalization-Constructors","page":"Home","title":"Normalization Constructors","text":"zscore(; method=:std) - Z-score normalization (standard, robust, or half-normal)\nminmax(; lower=0, upper=1) - Min-max scaling to custom range\nsigmoid() - Sigmoid transformation to (0, 1)\ncenter(; method=:mean) - Center data (mean or median)\nscale(; factor=:std) - Scale data (std or MAD)\nunitpower() - Unit RMS power normalization\npnorm(; p=2) - P-norm normalization\noutliersuppress(; thr=3.0) - Outlier suppression","category":"section"},{"location":"#Normalization-Functions-2","page":"Home","title":"Normalization Functions","text":"element_norm(X, n) - Normalize using global statistics\ntabular_norm(X, n; dim=:col) - Normalize columns/rows independently\nds_norm(X, n) - Normalize datasets with n-dimensional elements\ngrouped_norm(X, n; featvec) - Normalize grouped columns together\ngrouped_norm!(X, n; featvec) - In-place grouped normalization","category":"section"},{"location":"#Use-Cases","page":"Home","title":"Use Cases","text":"Audio Processing: Extract features from spectrograms for audio classification\nImage Analysis: Process image patches for computer vision tasks\nTime Series: Analyze segmented multivariate time series\nSignal Processing: Extract statistical features from signal windows\nMedical Data: Process multi-channel physiological signals\nExperiment Reproducibility: All parameters stored for exact replication","category":"section"},{"location":"#License","page":"Home","title":"License","text":"MIT License","category":"section"},{"location":"#About","page":"Home","title":"About","text":"Developed by the ACLAI Lab @ University of Ferrara.","category":"section"}]
}
